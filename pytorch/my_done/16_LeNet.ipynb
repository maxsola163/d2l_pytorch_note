{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "\n",
    "开始用于手写的数字识别\n",
    "\n",
    "- input : 32x32\n",
    "- c1 : 6@28x28\n",
    "- p1 : 6@14x14\n",
    "- c3 : 16@10x10\n",
    "- p4 : 16@5x5\n",
    "- Linear : 400 > 120\n",
    "- Linear : 120 > 84\n",
    "- Linear : 84 > 10\n",
    "\n",
    "Conclusion\n",
    "\n",
    "- `LeNet`是早期成功的神经网络\n",
    "- 使用卷积层学习图片的空间信息\n",
    "- 使用全连接层映射到类别空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" LeNet-5 \"\"\"\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "\n",
    "class Reshape(torch.nn.Module):\n",
    "    def forward(self, X):\n",
    "        return X.view((-1, 1, 28, 28))\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    Reshape(),\n",
    "    # 由于数据集是28x28，填充到32x32应用LeNet-5\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "    torch.nn.Sigmoid(), # 那个时候没有 ReLU\n",
    "    torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Flatten(), # 保持第一个维度（批量），后面全部展平\n",
    "    torch.nn.Linear(16 * 5 * 5, 120),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(120, 84),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape : torch.Size([1, 1, 28, 28])\n",
      "Conv2d : torch.Size([1, 6, 28, 28])\n",
      "Sigmoid : torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d : torch.Size([1, 6, 14, 14])\n",
      "Conv2d : torch.Size([1, 16, 10, 10])\n",
      "Sigmoid : torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d : torch.Size([1, 16, 5, 5])\n",
      "Flatten : torch.Size([1, 400])\n",
      "Linear : torch.Size([1, 120])\n",
      "Sigmoid : torch.Size([1, 120])\n",
      "Linear : torch.Size([1, 84])\n",
      "Sigmoid : torch.Size([1, 84])\n",
      "Linear : torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(f\"{layer.__class__.__name__} : {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = None\n",
    "batch_size=256\n",
    "num_cpu_cores = os.cpu_count()\n",
    "trans = [torchvision.transforms.ToTensor()]\n",
    "if resize:\n",
    "    trans.insert(0, torchvision.transforms.Resize(resize))\n",
    "trans = torchvision.transforms.ToTensor()\n",
    "train_iter = torch.utils.data.DataLoader(torchvision.datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=trans), batch_size, shuffle=True, num_workers=num_cpu_cores)\n",
    "test_iter = torch.utils.data.DataLoader(torchvision.datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=trans), batch_size, shuffle=True, num_workers=num_cpu_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 累加器对象 \"\"\"\n",
    "class Accumulator: # 累加器对象\n",
    "    \"\"\" 在 n 个变量上累加 \"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n # python 语法 [0]*n将n个list连接在一起\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "        # zip() 将迭代器打包成元组\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "\"\"\" 与真实值对比 \"\"\"\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\" 分类问题，统计正确个数 \"\"\"\n",
    "    # y_hat 是二维矩阵，取每一行的最大值\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1) # 返回最大值对应的序号\n",
    "    cmp = y_hat.type(y.dtype) == y   # 保证 y 和 y_hat 类型相同\n",
    "    # cmp 是 bool 类型\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def evaluate_accuracy_gpu(net, data_iter):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    device = try_gpu() \n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def try_gpu(i = 0):\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f\"cuda:{i}\")\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "def train_gpu(net, train_iter, test_iter, num_epochs, lr):\n",
    "    device = try_gpu()\n",
    "    print(f'training on {device}')\n",
    "\n",
    "    def init_weight(m):\n",
    "        if type(m) == torch.nn.Linear or type(m) == torch.nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weight)\n",
    "\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(params=net.parameters(), lr=lr)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_l, train_acc, test_acc, time_l = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)\n",
    "        net.train()\n",
    "        start = time.perf_counter()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], accuracy(y_hat=y_hat, y=y), X.shape[0])\n",
    "        end = time.perf_counter()\n",
    "        train_l.append(metric[0] / metric[2])\n",
    "        train_acc.append(metric[1] / metric[2])\n",
    "        test_acc.append(evaluate_accuracy_gpu(net, test_iter))\n",
    "        time_l.append(end-start)\n",
    "        print(f\"Epoch {epoch+1}, Using Time : {time_l[-1]:.3f}, train_acc : {train_acc[-1]:.4f} test_acc : {test_acc[-1]:.4f}\")\n",
    "    \"\"\"绘图\"\"\"\n",
    "    backend_inline.set_matplotlib_formats(\"svg\")\n",
    "    plt.rcParams['figure.figsize']=(7, 5)\n",
    "    plt.plot(list(range(num_epochs)), train_l, 'm--')\n",
    "    plt.plot(list(range(num_epochs)), train_acc, 'r:')\n",
    "    plt.plot(list(range(num_epochs)), test_acc, 'g-')\n",
    "\n",
    "    plt.legend([\"train_loss\", \"train_accuracy\", \"test_accuracy\"])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('percent')\n",
    "    plt.title(f'{num_epochs} epochs')\n",
    "    plt.grid(True)\n",
    "\n",
    "    print(f\"Test accuracy : {test_acc[-1]:.3f}\")\n",
    "    print(f'{metric[2] * num_epochs / sum(time_l):.1f} examples/sec on {str(torch.cuda.get_device_name())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n",
      "Epoch 1, Using Time : 8.073, train_acc : 0.0990 test_acc : 0.1000\n",
      "Epoch 2, Using Time : 8.081, train_acc : 0.1097 test_acc : 0.1811\n",
      "Epoch 3, Using Time : 7.903, train_acc : 0.3939 test_acc : 0.5375\n",
      "Epoch 4, Using Time : 8.024, train_acc : 0.6036 test_acc : 0.6274\n",
      "Epoch 5, Using Time : 7.881, train_acc : 0.6690 test_acc : 0.6666\n",
      "Epoch 6, Using Time : 8.086, train_acc : 0.6962 test_acc : 0.6942\n",
      "Epoch 7, Using Time : 8.098, train_acc : 0.7174 test_acc : 0.7148\n",
      "Epoch 8, Using Time : 8.171, train_acc : 0.7324 test_acc : 0.7013\n",
      "Epoch 9, Using Time : 8.072, train_acc : 0.7431 test_acc : 0.7377\n",
      "Epoch 10, Using Time : 8.022, train_acc : 0.7524 test_acc : 0.7557\n",
      "Epoch 11, Using Time : 8.180, train_acc : 0.7592 test_acc : 0.7588\n",
      "Epoch 12, Using Time : 8.075, train_acc : 0.7670 test_acc : 0.7730\n",
      "Epoch 13, Using Time : 8.103, train_acc : 0.7758 test_acc : 0.7236\n",
      "Epoch 14, Using Time : 8.289, train_acc : 0.7838 test_acc : 0.7570\n",
      "Epoch 15, Using Time : 7.903, train_acc : 0.7922 test_acc : 0.7930\n",
      "Epoch 16, Using Time : 8.033, train_acc : 0.7973 test_acc : 0.7894\n",
      "Epoch 17, Using Time : 7.994, train_acc : 0.8014 test_acc : 0.8030\n",
      "Epoch 18, Using Time : 7.815, train_acc : 0.8088 test_acc : 0.8020\n",
      "Epoch 19, Using Time : 7.895, train_acc : 0.8159 test_acc : 0.8116\n",
      "Epoch 20, Using Time : 7.935, train_acc : 0.8172 test_acc : 0.7393\n",
      "Epoch 21, Using Time : 7.905, train_acc : 0.8228 test_acc : 0.8162\n",
      "Epoch 22, Using Time : 8.047, train_acc : 0.8262 test_acc : 0.7945\n",
      "Epoch 23, Using Time : 8.276, train_acc : 0.8270 test_acc : 0.8191\n",
      "Epoch 24, Using Time : 8.387, train_acc : 0.8325 test_acc : 0.7788\n",
      "Epoch 25, Using Time : 8.190, train_acc : 0.8351 test_acc : 0.7934\n",
      "Epoch 26, Using Time : 8.124, train_acc : 0.8374 test_acc : 0.8013\n",
      "Epoch 27, Using Time : 7.983, train_acc : 0.8394 test_acc : 0.8237\n",
      "Epoch 28, Using Time : 8.019, train_acc : 0.8439 test_acc : 0.8252\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.3, 35\n",
    "start = time.perf_counter()\n",
    "train_gpu(net, train_iter, test_iter, num_epochs, lr)\n",
    "end = time.perf_counter()\n",
    "print(f\"Total Time : {end-start:3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e68e5b16d81fa9059e1158f6a4d703d6dd8750a9ccfa1e75dbe04c34949a9a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
